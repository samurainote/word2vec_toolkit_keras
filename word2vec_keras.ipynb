{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec from half-scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=[\"I’m real cautious. I didn’t have any expensive tastes. I lived well within my means in a one-bedroom apartment and decided not to sacrifice quality of life.\", \n",
    "       \"Self-doubt is popularly considered a monster, something I should be working to outrun. But the further I wade into adulthood, and the more I notice platitudes of self-belief becoming prerequisites for doing anything, the more I think it might be self-doubt that keeps me going.\",\n",
    "       \"I finished that book and tried to get agents. This was really before the internet, so you’d go through the agents in the Writer’s Guide and highlight the ones that did science fiction.\",\n",
    "       \"The story of the relationship between self-doubt and self-esteem is hardly simple. Markway says that it’s important not to let negative thoughts master you; it can be helpful to ask yourself, 'Is this thought true?'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46, 86, 49, 17, 64, 14, 12, 76, 77, 17, 96, 66, 14, 45, 69, 35, 71, 10, 58, 54, 60, 95, 86, 16, 24, 5, 10, 91], [27, 90, 19, 41, 14, 71, 53, 90, 17, 99, 30, 71, 16, 84, 5, 60, 76, 17, 80, 44, 19, 60, 60, 20, 17, 74, 81, 10, 27, 78, 63, 10, 30, 57, 8, 60, 20, 17, 84, 34, 32, 30, 27, 90, 56, 53, 31, 58], [17, 38, 56, 64, 60, 41, 16, 81, 79, 60, 13, 63, 67, 60, 69, 53, 8, 71, 72, 60, 79, 35, 60, 18, 74, 60, 46, 60, 81, 56, 13, 37, 20], [60, 9, 10, 60, 43, 87, 27, 90, 60, 27, 18, 19, 79, 64, 46, 21, 56, 69, 27, 86, 16, 91, 23, 62, 66, 66, 34, 57, 30, 80, 16, 73, 10, 92, 60, 50, 53, 55]]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 100\n",
    "word2idx = [one_hot(text=text, n=vocab_size) for text in texts]\n",
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46 86 49 17 64 14 12 76 77 17 96 66 14 45 69 35 71 10 58 54 60 95 86 16\n",
      "  24  5 10 91  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [41 14 71 53 90 17 99 30 71 16 84  5 60 76 17 80 44 19 60 60 20 17 74 81\n",
      "  10 27 78 63 10 30 57  8 60 20 17 84 34 32 30 27 90 56 53 31 58]\n",
      " [17 38 56 64 60 41 16 81 79 60 13 63 67 60 69 53  8 71 72 60 79 35 60 18\n",
      "  74 60 46 60 81 56 13 37 20  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [60  9 10 60 43 87 27 90 60 27 18 19 79 64 46 21 56 69 27 86 16 91 23 62\n",
      "  66 66 34 57 30 80 16 73 10 92 60 50 53 55  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "pad_len = 45\n",
    "pad4idx = pad_sequences(word2idx, maxlen=pad_len, padding=\"post\")\n",
    "print(pad4idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.initializers import glorot_uniform, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec(vocab_size, embeded_dim, pad_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embeded_dim, input_length=pad_len, embeddings_initializer=uniform(seed=20190219)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=vocab_size, use_bias=True,kernel_initializer=glorot_uniform(seed=20190219)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"RMSprop\", metrics=[\"categorical_accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded_dim=200\n",
    "model = word2vec(vocab_size, embeded_dim, pad_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 45, 200)           20000     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               900100    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 920,100\n",
      "Trainable params: 920,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
